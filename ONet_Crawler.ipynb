{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mysession=requests.Session()\n",
    "html_text=mysession.get('https://www.onetonline.org/link/summary/11-3051.00').text\n",
    "soup = BeautifulSoup(html_text, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HTMLparser:\n",
    "    def __init__(self, HTMLdoc):\n",
    "        self.root = BeautifulSoup(HTMLdoc, 'html.parser')\n",
    "        for t in self.root(['script', 'style', 'meta', 'link', 'head', 'img']):\n",
    "            t.extract()\n",
    "        self.headSection = self.root.find('div', {'id': 'content'})\n",
    "        self.types = {'A': ['Tasks',\n",
    "                            'Knowledge',\n",
    "                            'Skills',\n",
    "                            'Abilities',\n",
    "                            'WorkActivities',\n",
    "                            'DetailedWorkActivities',\n",
    "                            'WorkContext',\n",
    "                            'WorkStyles'],\n",
    "                      'B': ['ToolsTechnology'],\n",
    "                      'C': ['Job Zone','Wages & Employment Trends'],\n",
    "                      'D': ['Education'],\n",
    "                      'E': ['Interests', 'Work Values'],\n",
    "                      'F': ['Occupation listing']\n",
    "                      }\n",
    "                \n",
    "    def display(self, *tag):\n",
    "        if not tag:\n",
    "            tag = self.root\n",
    "        print(tag.prettify())\n",
    "        \n",
    "    def head(self):\n",
    "        headTag = self.headSection.span.text\n",
    "        return headTag.split('-')[2].strip()\n",
    "    \n",
    "    def jobID(self):\n",
    "        headTag = self.headSection.span.text\n",
    "        return headTag.split()[0].strip()\n",
    "    \n",
    "    def description(self):\n",
    "        return self.headSection.find_all('p')[0].text\n",
    "    \n",
    "    def titles(self):\n",
    "        return [i.strip() for i in re.findall('([a-zA-Z0-9 ]+),', self.headSection.find_all('p')[1].text)]\n",
    "    \n",
    "    def dictParser(self, text, convertList=False):\n",
    "        newDict = {}\n",
    "        text = re.sub('[^\\x00-\\x7F]', '', text)\n",
    "        text = re.sub('[\\\"\\']', '', text)\n",
    "        for i in text.split('\\n'):\n",
    "            if i:\n",
    "                try:\n",
    "                    newPair = i.split('â€”')\n",
    "                    newDict[newPair[0].strip()] = newPair[1].strip()\n",
    "                except IndexError:\n",
    "                    newDict[newPair[0].strip()] = None\n",
    "        if convertList and not any(newDict.values()):\n",
    "            newDict = list(newDict)\n",
    "        return newDict\n",
    "    \n",
    "    def tableParser(self, trs):\n",
    "        newDict = {}\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td')\n",
    "            try:\n",
    "                key = re.sub('[^\\x00-\\x7F]', '', tds[0].text) \n",
    "                key = text = re.sub('[\\\"\\']', '', key)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            if key:\n",
    "                try: \n",
    "                    value = re.sub('[^\\x00-\\x7F]', '', tds[1].text) \n",
    "                    value = re.sub('[\\\"\\']', '', value)\n",
    "                    newDict[key.strip()] = value.strip()        \n",
    "                except IndexError:\n",
    "                    value = None\n",
    "                    newDict[key.strip()] = value  \n",
    "        return newDict\n",
    "      \n",
    "    def typeAParser(self, section):  # list 1 section\n",
    "        try:\n",
    "            headTag = self.headSection.find('div', {'class': 'section_' + section}, recursive=False)\n",
    "            return self.dictParser(headTag.find_all('ul')[0].text)\n",
    "        except AttributeError:\n",
    "            return None   \n",
    "    \n",
    "    def typeBParser(self, section):  # list 2 sections\n",
    "        try:\n",
    "            headTag = self.headSection.find('div', {'class': 'section_' + section}, recursive=False)\n",
    "            uls = headTag.find_all('ul')\n",
    "            for ul in uls:\n",
    "                yield self.dictParser(ul.text)\n",
    "            yield None\n",
    "        except AttributeError:\n",
    "            for i in range(3):\n",
    "                yield None\n",
    "    \n",
    "    def typeCParser(self, section):  # table no headline\n",
    "        try:\n",
    "            headTag = self.headSection.find('table', \n",
    "                                            {'summary': section + ' information for this occupation'}, \n",
    "                                            recursive=True)\n",
    "            tableItem = headTag.find_all('tr')\n",
    "            return self.tableParser(tableItem)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def typeDParser(self, section): # table with headline\n",
    "        try:\n",
    "            headTag = self.headSection.find('table', \n",
    "                                            {'summary': section + ' information for this occupation'}, \n",
    "                                            recursive=True)\n",
    "            tableItem = headTag.find_all('tr')[1:]\n",
    "            return self.tableParser(tableItem)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def typeEParser(self, section):  # find in next closet siblings\n",
    "        try:\n",
    "            nextNode = self.headSection.find('h3', text=section, recursive=False)\n",
    "            while True:\n",
    "                nextNode = nextNode.nextSibling\n",
    "                if nextNode.name == 'ul':\n",
    "                    return self.dictParser(nextNode.text)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "            \n",
    "    def typeFParser(self, section):  # table no headline\n",
    "        try:\n",
    "            headTag = self.headSection.find('table', \n",
    "                                            {'summary': section}, \n",
    "                                            recursive=True)\n",
    "            tableItem = headTag.find_all('tr')\n",
    "            return self.tableParser(tableItem)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "            \n",
    "    def parse(self):\n",
    "        self.features = {}\n",
    "        self.features['id'] = self.jobID()\n",
    "        self.features['name'] = self.head()\n",
    "        self.features['description'] = self.description()\n",
    "        self.features['titles'] = self.titles()\n",
    "        for oneType, sections in self.types.items():\n",
    "            if oneType == 'B':\n",
    "                try:\n",
    "                    self.features['Tools'], self.features['Technology'] = list(self.typeBParser(sections[0]))[0:2]\n",
    "                except AttributeError:\n",
    "                    self.features['Tools'], self.features['Technology'] = (None, None)\n",
    "            else:\n",
    "                for oneSection in sections:\n",
    "                    try:\n",
    "                        self.features[oneSection] = getattr(self, 'type' + oneType + 'Parser')(oneSection)\n",
    "                    except AttributeError:\n",
    "                        self.features[oneSection] = None\n",
    "        return self.features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCodes(fname='ONET_code.csv'):\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    return df[1]\n",
    "\n",
    "df = readCodes()\n",
    "\n",
    "def readDescrip(df):\n",
    "    datalist = []\n",
    "    session = requests.Session()\n",
    "    mainUrl = 'https://www.onetonline.org/link/summary/'\n",
    "    for code in df:\n",
    "        print(code)\n",
    "        time.sleep(0.1)\n",
    "        codehtml = session.get(mainUrl + str(code))\n",
    "        datalist.append(HTMLparser(codehtml.text).parse())\n",
    "    alljobs = pd.DataFrame(datalist)\n",
    "    alljobs.to_csv('jobdescription.csv')\n",
    "        \n",
    "readDescrip(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('jobdescription.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cellParser(string):\n",
    "    if isinstance(string, (int, float, complex, list, dict, set)):\n",
    "        return string\n",
    "    if str(string) == 'nan':\n",
    "        return None\n",
    "    if re.search('^\\[.*\\]$', string):\n",
    "        return [i.strip() for i in re.sub('(\\'|\\\")', '', string[1:-1]).split(',')]\n",
    "    if re.search('^\\{.*\\}$', string):\n",
    "        string = re.sub('(?<=\\W)\\'(?!=\\W)', '\\\"', string)\n",
    "        string = re.sub('(?<!\\W)\\'(?=\\W)', '\\\"', string)\n",
    "        string = re.sub('None', '\\\"None\\\"', string)\n",
    "        string = re.sub('(?<!\\W),', ' ', string)\n",
    "        try:\n",
    "            return json.loads(string)\n",
    "        except:\n",
    "            print(string)\n",
    "            print()\n",
    "            print()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    df[column] = df[column].apply(lambda x: cellParser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
